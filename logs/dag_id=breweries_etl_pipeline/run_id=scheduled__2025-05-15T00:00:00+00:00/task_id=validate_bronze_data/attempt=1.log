[2025-05-16T00:03:34.138+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [queued]>
[2025-05-16T00:03:34.166+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [queued]>
[2025-05-16T00:03:34.167+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-05-16T00:03:34.189+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): validate_bronze_data> on 2025-05-15 00:00:00+00:00
[2025-05-16T00:03:34.197+0000] {standard_task_runner.py:60} INFO - Started process 9586 to run task
[2025-05-16T00:03:34.208+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'breweries_etl_pipeline', 'validate_bronze_data', 'scheduled__2025-05-15T00:00:00+00:00', '--job-id', '214', '--raw', '--subdir', 'DAGS_FOLDER/breweries_pipeline.py', '--cfg-path', '/tmp/tmph9j7qrlg']
[2025-05-16T00:03:34.212+0000] {standard_task_runner.py:88} INFO - Job 214: Subtask validate_bronze_data
[2025-05-16T00:03:34.273+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:194: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2025-05-16T00:03:34.385+0000] {task_command.py:423} INFO - Running <TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [running]> on host dd755db511a0
[2025-05-16T00:03:34.573+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='breweries_etl_pipeline' AIRFLOW_CTX_TASK_ID='validate_bronze_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-15T00:00:00+00:00'
[2025-05-16T00:03:34.578+0000] {logging_mixin.py:188} INFO - ðŸ”¸ Verificando camada Bronze
[2025-05-16T00:04:18.871+0000] {logging_mixin.py:188} INFO - âœ… Bronze OK
[2025-05-16T00:04:19.442+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-05-16T00:04:19.478+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=breweries_etl_pipeline, task_id=validate_bronze_data, execution_date=20250515T000000, start_date=20250516T000334, end_date=20250516T000419
[2025-05-16T00:05:31.573+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-16T00:05:31.675+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-16T09:11:54.124+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [queued]>
[2025-05-16T09:11:54.129+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [queued]>
[2025-05-16T09:11:54.130+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-05-16T09:11:54.138+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): validate_bronze_data> on 2025-05-15 00:00:00+00:00
[2025-05-16T09:11:54.143+0000] {standard_task_runner.py:60} INFO - Started process 61 to run task
[2025-05-16T09:11:54.147+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'breweries_etl_pipeline', 'validate_bronze_data', 'scheduled__2025-05-15T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/breweries_pipeline.py', '--cfg-path', '/tmp/tmpl_kifak9']
[2025-05-16T09:11:54.149+0000] {standard_task_runner.py:88} INFO - Job 14: Subtask validate_bronze_data
[2025-05-16T09:11:54.162+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:194: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2025-05-16T09:11:54.197+0000] {task_command.py:423} INFO - Running <TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [running]> on host 9264811a0e0a
[2025-05-16T09:11:54.264+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='breweries_etl_pipeline' AIRFLOW_CTX_TASK_ID='validate_bronze_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-15T00:00:00+00:00'
[2025-05-16T09:11:54.265+0000] {logging_mixin.py:188} INFO - ðŸ”¸ Verificando camada Bronze
[2025-05-16T09:11:54.448+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/src/validate.py", line 19, in validate_bronze_data
    spark = create_spark_session("ValidateBronze")
  File "/opt/airflow/dags/src/spark_utils.py", line 12, in create_spark_session
    return SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2025-05-16T09:11:54.456+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=breweries_etl_pipeline, task_id=validate_bronze_data, execution_date=20250515T000000, start_date=20250516T091154, end_date=20250516T091154
[2025-05-16T09:11:54.456+0000] {logging_mixin.py:188} INFO - 
    ðŸš¨ Falha na DAG breweries_etl_pipeline
    Tarefa: validate_bronze_data
    ExecuÃ§Ã£o: 2025-05-15 00:00:00+00:00
    Erro: Java gateway process exited before sending its port number
    
[2025-05-16T09:11:54.464+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/utils/email.py:154: RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2025-05-16T09:11:54.465+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2025-05-16T09:11:54.465+0000] {email.py:270} INFO - Email alerting: attempt 1
[2025-05-16T09:11:54.466+0000] {taskinstance.py:1116} ERROR - Error when executing failure_alert callback
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2334, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2499, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2516, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/src/validate.py", line 19, in validate_bronze_data
    spark = create_spark_session("ValidateBronze")
  File "/opt/airflow/dags/src/spark_utils.py", line 12, in create_spark_session
    return SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1113, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/breweries_pipeline.py", line 26, in failure_alert
    send_email(to="devteam@example.com", subject="ðŸš¨ Airflow Task Failure", html_content=message)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.8/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.8/smtplib.py", line 339, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.8/smtplib.py", line 310, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.8/socket.py", line 808, in create_connection
    raise err
  File "/usr/local/lib/python3.8/socket.py", line 796, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-05-16T09:11:54.474+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 14 for task validate_bronze_data (Java gateway process exited before sending its port number; 61)
[2025-05-16T09:11:54.496+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-05-16T09:11:54.517+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-16T09:12:43.065+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [queued]>
[2025-05-16T09:12:43.073+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [queued]>
[2025-05-16T09:12:43.075+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-05-16T09:12:43.090+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): validate_bronze_data> on 2025-05-15 00:00:00+00:00
[2025-05-16T09:12:43.474+0000] {standard_task_runner.py:60} INFO - Started process 124 to run task
[2025-05-16T09:12:43.535+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'breweries_etl_pipeline', 'validate_bronze_data', 'scheduled__2025-05-15T00:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/breweries_pipeline.py', '--cfg-path', '/tmp/tmp8e05tgu8']
[2025-05-16T09:12:43.541+0000] {standard_task_runner.py:88} INFO - Job 20: Subtask validate_bronze_data
[2025-05-16T09:12:43.640+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:194: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2025-05-16T09:12:43.740+0000] {task_command.py:423} INFO - Running <TaskInstance: breweries_etl_pipeline.validate_bronze_data scheduled__2025-05-15T00:00:00+00:00 [running]> on host 9264811a0e0a
[2025-05-16T09:12:43.840+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='breweries_etl_pipeline' AIRFLOW_CTX_TASK_ID='validate_bronze_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-15T00:00:00+00:00'
[2025-05-16T09:12:43.841+0000] {logging_mixin.py:188} INFO - ðŸ”¸ Verificando camada Bronze
[2025-05-16T09:12:44.047+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/src/validate.py", line 19, in validate_bronze_data
    spark = create_spark_session("ValidateBronze")
  File "/opt/airflow/dags/src/spark_utils.py", line 12, in create_spark_session
    return SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2025-05-16T09:12:44.054+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=breweries_etl_pipeline, task_id=validate_bronze_data, execution_date=20250515T000000, start_date=20250516T091243, end_date=20250516T091244
[2025-05-16T09:12:44.054+0000] {logging_mixin.py:188} INFO - 
    ðŸš¨ Falha na DAG breweries_etl_pipeline
    Tarefa: validate_bronze_data
    ExecuÃ§Ã£o: 2025-05-15 00:00:00+00:00
    Erro: Java gateway process exited before sending its port number
    
[2025-05-16T09:12:44.059+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/utils/email.py:154: RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2025-05-16T09:12:44.059+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2025-05-16T09:12:44.059+0000] {email.py:270} INFO - Email alerting: attempt 1
[2025-05-16T09:12:44.060+0000] {taskinstance.py:1116} ERROR - Error when executing failure_alert callback
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2334, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2499, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2516, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/src/validate.py", line 19, in validate_bronze_data
    spark = create_spark_session("ValidateBronze")
  File "/opt/airflow/dags/src/spark_utils.py", line 12, in create_spark_session
    return SparkSession.builder \
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1113, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/breweries_pipeline.py", line 26, in failure_alert
    send_email(to="devteam@example.com", subject="ðŸš¨ Airflow Task Failure", html_content=message)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.8/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.8/smtplib.py", line 339, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.8/smtplib.py", line 310, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.8/socket.py", line 808, in create_connection
    raise err
  File "/usr/local/lib/python3.8/socket.py", line 796, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-05-16T09:12:44.071+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 20 for task validate_bronze_data (Java gateway process exited before sending its port number; 124)
[2025-05-16T09:12:44.105+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-05-16T09:12:44.133+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
